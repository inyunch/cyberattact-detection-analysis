# MICE Imputation Guide

## Overview

This guide explains how to use the MICE (Multiple Imputation by Chained Equations) imputation workflow in the CyberGuard Dashboard project.

## Files Created

### 1. Data Files

#### Input Data
- **Location:** `data/global_threat_landscape_with_missing.csv`
- **Description:** Global threat dataset with 20% missing values in the "Financial Loss (in Million $)" column
- **Size:** 3,000 records with 10 columns
- **Missing Values:** 600 records (20%)

#### Output Data (Generated by Notebook)
- **Location:** `data/global_threat_landscape_imputed.csv`
- **Description:** Same dataset with missing values imputed using MICE
- **Usage:** Can be loaded in app.py for visualization

- **Location:** `data/imputation_comparison.csv`
- **Description:** Comparison data showing Original, With_Missing, Imputed, and Was_Missing columns
- **Usage:** For quality assessment and validation

- **Location:** `data/mice_imputation_results.png`
- **Description:** Comprehensive visualization of imputation results
- **Usage:** For presentation and documentation

### 2. Scripts

#### Data Generation Script
- **Location:** `scripts/generate_missing_data.py`
- **Purpose:** Generates dataset with missing values from original data
- **Usage:**
  ```bash
  python scripts/generate_missing_data.py
  ```
- **Output:** Creates `global_threat_landscape_with_missing.csv`

### 3. Notebooks

#### MICE Imputation Notebook
- **Location:** `notebooks/mice_imputation_demo.ipynb`
- **Purpose:** Demonstrates MICE imputation process with visualizations
- **Features:**
  - Loads data with missing values
  - Performs MICE imputation using Random Forest
  - Compares original vs imputed values
  - Calculates quality metrics (MAE, RMSE, MAPE)
  - Generates visualizations
  - Saves imputed dataset

## Workflow

### Step 1: Generate Missing Data

```bash
cd C:\Repo\Github\cyberattact-detection-analysis
python scripts/generate_missing_data.py
```

**Output:**
```
================================================================================
GENERATING DATASET WITH MISSING VALUES
================================================================================

1. Loading original dataset...
   [OK] Loaded 3,000 records with 10 columns
   [OK] Original missing values in Financial Loss: 0

2. Introducing 20% missing values in 'Financial Loss (in Million $)'
   [OK] Missing values introduced: 600 (20.00%)

3. Saving dataset with missing values...
   [OK] Dataset saved successfully!

[SUCCESS] Dataset generation complete!
[SUCCESS] Output file: data/global_threat_landscape_with_missing.csv
================================================================================
```

### Step 2: Run MICE Imputation

1. Open Jupyter Notebook:
   ```bash
   jupyter notebook notebooks/mice_imputation_demo.ipynb
   ```

2. Run all cells in the notebook

3. Review the output:
   - Imputation quality metrics
   - Visualizations
   - Statistical comparisons

### Step 3: Use Imputed Data in Dashboard

The imputed dataset can now be used in the dashboard for visualization and analysis.

## Imputation Quality Metrics

The notebook calculates three key quality metrics:

1. **MAE (Mean Absolute Error)**
   - Average absolute difference between original and imputed values
   - Lower is better
   - Measured in $M

2. **RMSE (Root Mean Squared Error)**
   - Square root of average squared differences
   - Penalizes large errors more than MAE
   - Measured in $M

3. **MAPE (Mean Absolute Percentage Error)**
   - Average percentage error
   - Scale-independent metric
   - Quality assessment:
     - < 10%: Excellent
     - 10-20%: Good
     - > 20%: Moderate

## Visualization Outputs

The notebook generates four key visualizations:

### 1. Original vs Imputed Scatter Plot
- Shows how well imputed values match original values
- Perfect predictions lie on the diagonal line

### 2. Distribution Comparison
- Histogram comparing original vs imputed distributions
- Ensures imputation preserves distribution shape

### 3. Imputation Error Distribution
- Histogram of prediction errors
- Should be centered around zero

### 4. Box Plot Comparison
- Compares statistical properties (median, quartiles, outliers)
- Validates that imputation doesn't distort data

## Integration with Dashboard

### Option 1: Add as New Data Source

Modify `app.py` to load the imputed dataset:

```python
@st.cache_data
def load_data():
    # Original data
    global_threats = pd.read_csv('data/Global_Cybersecurity_Threats_2015-2024.csv')

    # Data with missing values
    global_threats_missing = pd.read_csv('data/global_threat_landscape_with_missing.csv')

    # Imputed data
    global_threats_imputed = pd.read_csv('data/global_threat_landscape_imputed.csv')

    intrusion_data = pd.read_csv('data/cybersecurity_intrusion_data.csv')

    return global_threats, global_threats_missing, global_threats_imputed, intrusion_data
```

### Option 2: Add Comparison Visualization

Create a new page to compare datasets:

```python
def show_imputation_comparison():
    st.title("MICE Imputation Analysis")

    # Load comparison data
    comparison_df = pd.read_csv('data/imputation_comparison.csv')

    # Display visualizations
    st.image('data/mice_imputation_results.png')

    # Show metrics
    imputed_only = comparison_df[comparison_df['Was_Missing'] == True]
    mae = abs(imputed_only['Original'] - imputed_only['Imputed']).mean()

    st.metric("Mean Absolute Error", f"${mae:.2f}M")
```

## Technical Details

### MICE Algorithm Parameters

```python
IterativeImputer(
    estimator=RandomForestRegressor(n_estimators=10, random_state=42),
    max_iter=10,  # Number of imputation rounds
    random_state=42,  # For reproducibility
    verbose=1  # Show progress
)
```

### Features Used for Imputation

1. **Year** - Temporal context
2. **Incident Resolution Time** - Related to severity
3. **Financial Loss** - Target variable (with missing values)
4. **Number of Affected Users** - Related to impact

## Best Practices

1. **Always keep original data intact**
   - Never overwrite original files
   - Save imputed data separately

2. **Document imputation decisions**
   - Record which columns were imputed
   - Note the imputation method used
   - Save quality metrics

3. **Validate results**
   - Check distribution preservation
   - Verify statistical properties
   - Compare with domain knowledge

4. **Communicate limitations**
   - Imputation is prediction, not truth
   - Uncertainty exists in imputed values
   - Consider multiple imputation for uncertainty quantification

## Troubleshooting

### Issue: High MAPE (> 20%)

**Solutions:**
- Add more features to the imputation model
- Try different estimators (e.g., BayesianRidge, ExtraTreesRegressor)
- Increase `max_iter` for better convergence

### Issue: Distribution doesn't match

**Solutions:**
- Check for outliers in original data
- Consider log-transformation for skewed data
- Use stratified imputation for categorical groups

### Issue: Notebook fails to run

**Solutions:**
- Verify all packages are installed:
  ```bash
  pip install pandas numpy matplotlib seaborn scikit-learn
  ```
- Check file paths (use `../data/` from notebooks directory)
- Ensure data files exist in `data/` directory

## References

- van Buuren, S., & Groothuis-Oudshoorn, K. (2011). mice: Multivariate Imputation by Chained Equations in R. *Journal of Statistical Software*, 45(3).
- Scikit-learn IterativeImputer documentation: https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html

## Support

For questions or issues:
1. Check the notebook output for error messages
2. Review the quality metrics
3. Consult the visualization outputs
4. Refer to this guide for troubleshooting

---

**Last Updated:** 2025-10-15
